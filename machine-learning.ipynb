{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3451,"sourceType":"datasetVersion","datasetId":2019},{"sourceId":1760012,"sourceType":"datasetVersion","datasetId":1046158},{"sourceId":2874008,"sourceType":"datasetVersion","datasetId":1760177},{"sourceId":9551482,"sourceType":"datasetVersion","datasetId":5819644}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\ncrop_data = pd.read_csv('/kaggle/input/crop-recommendation-dataset/Crop_recommendation.csv')\n\n\nprint(crop_data.columns)\n\n\ncrop_type_column = 'label'  # Replace with the actual column name\n\n# Encode the target variable (crop type)\nle = LabelEncoder()\ncrop_data[crop_type_column] = le.fit_transform(crop_data[crop_type_column])\n\n# Normalize numerical features\nscaler = StandardScaler()\nnumerical_features = ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']\ncrop_data[numerical_features] = scaler.fit_transform(crop_data[numerical_features])\n\n# Define features and target variable\nX = crop_data[numerical_features]\ny = crop_data[crop_type_column]\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize the model\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Train the model\nmodel.fit(X_train, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test)\n\n# Calculate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Accuracy: {accuracy}')\n\n# Display classification report\nprint(classification_report(y_test, y_pred, target_names=le.classes_))\n\n# Example input data with feature names\ninput_data = pd.DataFrame([[90, 42, 43, 20.87, 82.00, 6.5, 202.93]], columns=numerical_features)\n\n# Normalize the input data\ninput_data = scaler.transform(input_data)\n\n# Predict the crop\npredicted_crop = model.predict(input_data)\npredicted_crop_name = le.inverse_transform(predicted_crop)\nprint(f'Recommended Crop: {predicted_crop_name}')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-05T08:18:20.604995Z","iopub.execute_input":"2024-10-05T08:18:20.606437Z","iopub.status.idle":"2024-10-05T08:18:21.179463Z","shell.execute_reply.started":"2024-10-05T08:18:20.606381Z","shell.execute_reply":"2024-10-05T08:18:21.178254Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Index(['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall', 'label'], dtype='object')\nAccuracy: 0.9931818181818182\n              precision    recall  f1-score   support\n\n       apple       1.00      1.00      1.00        23\n      banana       1.00      1.00      1.00        21\n   blackgram       1.00      1.00      1.00        20\n    chickpea       1.00      1.00      1.00        26\n     coconut       1.00      1.00      1.00        27\n      coffee       1.00      1.00      1.00        17\n      cotton       1.00      1.00      1.00        17\n      grapes       1.00      1.00      1.00        14\n        jute       0.92      1.00      0.96        23\n kidneybeans       1.00      1.00      1.00        20\n      lentil       0.92      1.00      0.96        11\n       maize       1.00      1.00      1.00        21\n       mango       1.00      1.00      1.00        19\n   mothbeans       1.00      0.96      0.98        24\n    mungbean       1.00      1.00      1.00        19\n   muskmelon       1.00      1.00      1.00        17\n      orange       1.00      1.00      1.00        14\n      papaya       1.00      1.00      1.00        23\n  pigeonpeas       1.00      1.00      1.00        23\n pomegranate       1.00      1.00      1.00        23\n        rice       1.00      0.89      0.94        19\n  watermelon       1.00      1.00      1.00        19\n\n    accuracy                           0.99       440\n   macro avg       0.99      0.99      0.99       440\nweighted avg       0.99      0.99      0.99       440\n\nRecommended Crop: ['rice']\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\n# Load your crop nutrient data\ndata = pd.read_csv('/kaggle/input/crop-nutrient-database/crops.csv')\n\n# Print the column names to identify the correct features\nprint(data.columns)\n\n# Replace 'feature1', 'feature2', 'feature3' with actual column names from your dataset\n# For example, let's use 'AvN%(dry)', 'AvMoisture%', and 'AvYieldUnitWeight(lb)' as features\nX = data[['AvN%(dry)', 'AvMoisture%', 'AvYieldUnitWeight(lb)']]  # Replace with your actual feature columns\ny = data['AvYieldUnitWeight(lb)']  # Replace with your actual target column\n\n# Clean the data by replacing non-numeric values with NaN and then filling them with the mean of the column\nX = X.apply(pd.to_numeric, errors='coerce')\nX.fillna(X.mean(), inplace=True)\n\n# Ensure the target column is numeric and handle NaN values\ny = pd.to_numeric(y, errors='coerce')\ny.fillna(y.mean(), inplace=True)\n\n# Check for any remaining NaN values\nprint(X.isna().sum())\nprint(y.isna().sum())\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Standardize the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train the model\nmodel = RandomForestRegressor()\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Evaluate the model\nmse = mean_squared_error(y_test, y_pred)\nprint(f'Mean Squared Error: {mse}')\n\n# Save the model for future use\nimport joblib\njoblib.dump(model, 'nutrient_management_model.pkl')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-05T08:14:12.491474Z","iopub.execute_input":"2024-10-05T08:14:12.492180Z","iopub.status.idle":"2024-10-05T08:14:14.643076Z","shell.execute_reply.started":"2024-10-05T08:14:12.492102Z","shell.execute_reply":"2024-10-05T08:14:14.641367Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Index(['Crop', 'ScientificName', 'Symbol', 'NuContAvailable',\n       'PlantPartHarvested', 'CropCategory', 'YieldUnit',\n       'AvYieldUnitWeight(lb)', 'AvMoisture%', 'AvN%(dry)',\n       ...\n       'N%(wet)_M-FF', 'P%(wet)_M-FF', 'gP/100g(wet)_AgH8-9',\n       'gP/100g(wet)_AgH8-12', 'gP/100g(wet)_B788', 'P%(wet)_M&L',\n       'K%(wet)_M-FF', 'gK/100g(wet)_AgH8-9', 'gK/100g(wet)_AgH8-12',\n       'gK/100g(wet)_B788'],\n      dtype='object', length=161)\nAvN%(dry)                0\nAvMoisture%              0\nAvYieldUnitWeight(lb)    0\ndtype: int64\n0\nMean Squared Error: 17.680802753277028\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"['nutrient_management_model.pkl']"},"metadata":{}}]},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\n# Define the directory path and file name\ndirectory_path = '/kaggle/input/crop-yield-prediction-dataset'\nfile_name = 'yield.csv'\nfile_path = os.path.join(directory_path, file_name)\n\n# Load the new data\nnew_data = pd.read_csv(file_path)\n\n# Print the first few rows to understand the structure\nprint(new_data.head())\n\n# Select the feature columns (adjust column names as needed)\n# Using 'Year' and 'Item' as features for simplicity\nX_new = new_data[['Year', 'Item']]\n\n# Convert categorical 'Item' column to numeric using one-hot encoding\nX_new = pd.get_dummies(X_new, columns=['Item'])\n\n# Clean the new data by replacing non-numeric values with NaN and then filling them with the mean of the column\nX_new = X_new.apply(pd.to_numeric, errors='coerce')\nX_new.fillna(X_new.mean(), inplace=True)\n\n# Standardize the features\nscaler = StandardScaler()\nX_new_scaled = scaler.fit_transform(X_new)\n\n# Initialize and train the model (using the same steps as before)\nmodel = RandomForestRegressor()\nmodel.fit(X_new_scaled, new_data['Value'])  # Assuming 'Value' is the target column\n\n# Make predictions\npredictions = model.predict(X_new_scaled)\n\n# Print the predictions\nprint(predictions)\n\n# Evaluate the model (optional, if you have a test set)\nmse = mean_squared_error(new_data['Value'], predictions)\nprint(f'Mean Squared Error: {mse}')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-05T08:14:15.689318Z","iopub.execute_input":"2024-10-05T08:14:15.689748Z","iopub.status.idle":"2024-10-05T08:14:19.882537Z","shell.execute_reply.started":"2024-10-05T08:14:15.689703Z","shell.execute_reply":"2024-10-05T08:14:19.880901Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"  Domain Code Domain  Area Code         Area  Element Code Element  Item Code  \\\n0          QC  Crops          2  Afghanistan          5419   Yield         56   \n1          QC  Crops          2  Afghanistan          5419   Yield         56   \n2          QC  Crops          2  Afghanistan          5419   Yield         56   \n3          QC  Crops          2  Afghanistan          5419   Yield         56   \n4          QC  Crops          2  Afghanistan          5419   Yield         56   \n\n    Item  Year Code  Year   Unit  Value  \n0  Maize       1961  1961  hg/ha  14000  \n1  Maize       1962  1962  hg/ha  14000  \n2  Maize       1963  1963  hg/ha  14260  \n3  Maize       1964  1964  hg/ha  14257  \n4  Maize       1965  1965  hg/ha  14400  \n[14619.18291952 15035.67381969 15257.70782441 ... 32960.20022852\n 34060.07496573 33553.80456013]\nMean Squared Error: 2328859297.9933157\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\n# Load the dataset\ndata = pd.read_csv('/kaggle/input/crop-yield-prediction-dataset/yield.csv')\n\n# Inspect the data\nprint(data.head())\n\n# Select relevant features\n# Using 'Year' and 'Item' as features for simplicity\nfeatures = ['Year', 'Item']\nX = data[features]\ny = data['Value']  # Assuming 'Value' is the target column representing yield\n\n# Convert categorical 'Item' column to numeric using one-hot encoding\nX = pd.get_dummies(X, columns=['Item'])\n\n# Clean the data by replacing non-numeric values with NaN and then filling them with the mean of the column\nX = X.apply(pd.to_numeric, errors='coerce')\nX.fillna(X.mean(), inplace=True)\n\n# Ensure the target column is numeric and handle NaN values\ny = pd.to_numeric(y, errors='coerce')\ny.fillna(y.mean(), inplace=True)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Standardize the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train the model\nmodel = RandomForestRegressor()\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Evaluate the model\nmse = mean_squared_error(y_test, y_pred)\nprint(f'Mean Squared Error: {mse}')\n\n# Save the model for future use\nimport joblib\njoblib.dump(model, 'improved_crop_yield_model.pkl')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-05T08:14:19.885743Z","iopub.execute_input":"2024-10-05T08:14:19.886771Z","iopub.status.idle":"2024-10-05T08:14:23.275021Z","shell.execute_reply.started":"2024-10-05T08:14:19.886717Z","shell.execute_reply":"2024-10-05T08:14:23.273456Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"  Domain Code Domain  Area Code         Area  Element Code Element  Item Code  \\\n0          QC  Crops          2  Afghanistan          5419   Yield         56   \n1          QC  Crops          2  Afghanistan          5419   Yield         56   \n2          QC  Crops          2  Afghanistan          5419   Yield         56   \n3          QC  Crops          2  Afghanistan          5419   Yield         56   \n4          QC  Crops          2  Afghanistan          5419   Yield         56   \n\n    Item  Year Code  Year   Unit  Value  \n0  Maize       1961  1961  hg/ha  14000  \n1  Maize       1962  1962  hg/ha  14000  \n2  Maize       1963  1963  hg/ha  14260  \n3  Maize       1964  1964  hg/ha  14257  \n4  Maize       1965  1965  hg/ha  14400  \nMean Squared Error: 2409671809.0282454\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"['improved_crop_yield_model.pkl']"},"metadata":{}}]}]}